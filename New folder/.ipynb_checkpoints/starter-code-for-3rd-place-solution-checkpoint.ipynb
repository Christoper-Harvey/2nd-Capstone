{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['y_train.csv', 'sample_submission.csv', 'X_train.csv', 'X_test.csv']\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
    "\n",
    "import os\n",
    "print(os.listdir(\"../input\"))\n",
    "\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "testing = True #Set this to true for submission/False for cross validation\n",
    "X_train = pd.read_csv('../input/X_train.csv')\n",
    "y_train = pd.read_csv('../input/y_train.csv')\n",
    "X_train = pd.merge(X_train,y_train,on='series_id')\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "X_train['surface'] = le.fit_transform(X_train['surface'])\n",
    "if(testing):\n",
    "    X_test = pd.read_csv('../input/X_test.csv')\n",
    "    X_test['series_id'] = X_test['series_id']+3810\n",
    "    X_test['group_id'] = 0\n",
    "    X_test['surface'] = 0\n",
    "    frames = [X_train,X_test]\n",
    "    X_train = pd.concat(frames)\n",
    "    X_train.reset_index(drop=True,inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_uuid": "221072c02a371cac63d07e9592941c6e65bf8a42"
   },
   "outputs": [],
   "source": [
    "cols = list(X_train.columns.values)\n",
    "cols.remove('orientation_W')\n",
    "cols.insert(3,'orientation_W')\n",
    "X_train = X_train[cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_uuid": "71d24843e14f36b7c2b0860eea9b7d4c3e6f57a2",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "num_meas = 128\n",
    "num_series = X_train['series_id'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_uuid": "603241626d86bf9eeacb6ee9ed95d3ecec99e0fd",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def q_to_angle(q_val):\n",
    "    #We assume q_val is in this format: [qw, q1, q2, q3]\n",
    "    #And the quaternion is normalized\n",
    "    roll = np.arctan2(2*(q_val[0]*q_val[1] + q_val[2]*q_val[3]),1 - 2*(q_val[1]*q_val[1] + q_val[2]*q_val[2]))\n",
    "    pitch = np.arcsin(2*(q_val[0]*q_val[2] - q_val[3]*q_val[1]))\n",
    "    yaw = np.arctan2(2*(q_val[0]*q_val[3] + q_val[1]*q_val[2]),1 - 2*(q_val[2]*q_val[2] + q_val[3]*q_val[3]))\n",
    "    return np.array([roll, pitch, yaw])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_uuid": "cf416b97ff135f37f7287bb331b5ac25b442bd71",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "quat_arr = np.array(X_train[['orientation_W','orientation_X','orientation_Y','orientation_Z']])\n",
    "euler_arr = np.zeros([quat_arr.shape[0],3])\n",
    "for n,arr in enumerate(quat_arr):\n",
    "    euler_arr[n] = q_to_angle(arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_uuid": "83569b323e21d295b47e5f0a8053b21b96dd0298",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_train['roll'] = euler_arr[:,0]\n",
    "X_train['pitch'] = euler_arr[:,1]\n",
    "X_train['yaw'] = euler_arr[:,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "_uuid": "39e0baed88650cc85b720cdc098ba8288681ca44",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cols = list(X_train.columns.values)\n",
    "cols.remove('group_id')\n",
    "cols.append('group_id')\n",
    "cols.remove('surface')\n",
    "cols.append('surface')\n",
    "X_train = X_train[cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "_uuid": "6a61e694bf681474b358a0862004de4973b428d9",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "feat_cols = ['roll','pitch','yaw','angular_velocity_X','angular_velocity_Y','angular_velocity_Z','linear_acceleration_X','linear_acceleration_Y','linear_acceleration_Z']\n",
    "feat_array = np.array(X_train[feat_cols])\n",
    "feat_array = np.reshape(feat_array,[num_series,128,len(feat_cols)])\n",
    "group_array = np.array(X_train['group_id'])\n",
    "group_array = np.reshape(group_array,[num_series,128])\n",
    "group_array = group_array[:,0]\n",
    "target_array = np.array(X_train['surface'])\n",
    "target_array = np.reshape(target_array,[num_series,128])\n",
    "target_array = target_array[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "_uuid": "537abf133ddfbb65dd2c7e29f5ceee444facaeee",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Use the first order difference of the following features\n",
    "#Absolute Orientation features dont make sense to predict surface\n",
    "delta_cols = ['roll','pitch','yaw']\n",
    "for dc in delta_cols:\n",
    "    iia = feat_cols.index(dc)\n",
    "    np_arr = feat_array[:,:,iia]\n",
    "    roll_arr = np.copy(np_arr)\n",
    "    roll_arr[:,1:] = roll_arr[:,:-1]\n",
    "    np_arr = np_arr - roll_arr\n",
    "    feat_array[:,:,iia] = np_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "_uuid": "194f265bd2cba051f61b1b1d529e0ddf9b1c37c8"
   },
   "outputs": [],
   "source": [
    "#Normalize each 128-pt sample to ensure there is no group related information left in the samples\n",
    "norm_cols = ['linear_acceleration_X','linear_acceleration_Y','linear_acceleration_Z','angular_velocity_X','angular_velocity_Y','angular_velocity_Z']\n",
    "for norm in norm_cols:\n",
    "    iia = feat_cols.index(norm)\n",
    "    np_arr = feat_array[:,:,iia]\n",
    "    mean_arr = np.mean(np_arr,1)\n",
    "    mean_arr = np.expand_dims(mean_arr,1)\n",
    "    mean_arr = np.repeat(mean_arr,num_meas,1)\n",
    "    np_arr = np_arr - mean_arr\n",
    "    feat_array[:,:,iia] = np_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "_uuid": "a31f546817b501b93a4855db477aa043c56c22d8"
   },
   "outputs": [],
   "source": [
    "def absfft(x):\n",
    "    return np.abs(np.fft.rfft(x))\n",
    "\n",
    "feat_fft_array = np.copy(feat_array[:,:,3:])\n",
    "feat_fft_array = np.apply_along_axis(absfft,1,feat_fft_array)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "_uuid": "4b0c58012bd2144fcac6bb9f515340ab57393f07"
   },
   "outputs": [],
   "source": [
    "#Further normalization across the entire dataset to ensure NN inputs are zero-mean and unit standard deviation\n",
    "\n",
    "num_sensor = feat_array.shape[2]\n",
    "for i in range(num_sensor):\n",
    "    mean_s = np.mean(feat_array[:,:,i])\n",
    "    sd_s = np.std(feat_array[:,:,i])\n",
    "    feat_array[:,:,i] = (feat_array[:,:,i]-mean_s)/sd_s\n",
    "\n",
    "num_sensor_fft = feat_fft_array.shape[2]\n",
    "for i in range(num_sensor_fft):\n",
    "    mean_s = np.mean(feat_fft_array[:,:,i])\n",
    "    sd_s = np.std(feat_fft_array[:,:,i])\n",
    "    feat_fft_array[:,:,i] = (feat_fft_array[:,:,i]-mean_s)/sd_s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "_uuid": "495ca800870408b60542ee298087f4253726dad4",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Input,Dense, Dropout, BatchNormalization, SeparableConv1D, Reshape, LSTM, DepthwiseConv2D,AveragePooling2D, CuDNNLSTM, Concatenate\n",
    "from keras.models import Model\n",
    "from keras.backend import squeeze\n",
    "from keras.regularizers import l2\n",
    "kr = None\n",
    "num_groups = np.unique(group_array).shape[0]\n",
    "num_surfaces = np.unique(target_array).shape[0]\n",
    "\n",
    "def get_net_with_fft_mag_only(dp):\n",
    "    inputs_t = Input(shape=(128,len(feat_cols)))\n",
    "    x = SeparableConv1D(32,8,2,'same',depth_multiplier=1,activation='relu',kernel_regularizer=kr)(inputs_t)\n",
    "    x = Dropout(dp)(x)\n",
    "    x = SeparableConv1D(64,8,4,'same',depth_multiplier=1,activation='relu',kernel_regularizer=kr)(x)\n",
    "    x = Dropout(dp)(x)\n",
    "    x = SeparableConv1D(128,8,4,'same',depth_multiplier=1,activation='relu',kernel_regularizer=kr)(x)\n",
    "    x = Dropout(dp)(x)\n",
    "    x = SeparableConv1D(256,8,4,'same',depth_multiplier=1,activation='relu',kernel_regularizer=kr)(x)\n",
    "    x = Reshape((256,))(x)\n",
    "    x = Dropout(dp)(x)\n",
    "    x = Dense(64, activation='relu',kernel_regularizer=kr)(x)\n",
    "    x = Dropout(dp)(x)\n",
    "    x = Dense(64, activation='relu')(x)\n",
    "    \n",
    "    inputs_f = Input(shape=(feat_fft_array.shape[1],feat_fft_array.shape[2]))\n",
    "    y = SeparableConv1D(32,8,2,'same',depth_multiplier=1,activation='relu',kernel_regularizer=kr)(inputs_f)\n",
    "    y = Dropout(dp)(y)\n",
    "    y = SeparableConv1D(64,8,2,'same',depth_multiplier=1,activation='relu',kernel_regularizer=kr)(y)\n",
    "    y = Dropout(dp)(y)\n",
    "    y = SeparableConv1D(128,8,4,'same',depth_multiplier=1,activation='relu',kernel_regularizer=kr)(y)\n",
    "    y = Dropout(dp)(y)\n",
    "    y = SeparableConv1D(128,8,4,'same',depth_multiplier=1,activation='relu',kernel_regularizer=kr)(y)\n",
    "    y = Dropout(dp)(y)\n",
    "    y = SeparableConv1D(256,8,2,'same',depth_multiplier=1,activation='relu',kernel_regularizer=kr)(y)\n",
    "    y = Reshape((256,))(y)\n",
    "    y = Dropout(dp)(y)\n",
    "    y = Dense(64, activation='relu',kernel_regularizer=kr)(y)\n",
    "    y = Dropout(dp)(y)\n",
    "    y = Dense(64, activation='relu')(y)\n",
    "    \n",
    "        \n",
    "    inputs = [inputs_t,inputs_f]\n",
    "    \n",
    "    z = Concatenate()([x,y])\n",
    "    z = Dense(64, activation='relu')(z)\n",
    "    predictions = Dense(num_surfaces, activation='softmax')(z)\n",
    "    model = Model(inputs=inputs, outputs=predictions)\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss='sparse_categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "_uuid": "e384f3e8a2cc567b2c2a4be08bd2d05f6fd9d127"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GroupKFold, StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "depthwise = False\n",
    "fft_net = True\n",
    "if(not(testing)):\n",
    "    gkf = GroupKFold(3)\n",
    "    train_gen = gkf.split(X=feat_array,groups=group_array)\n",
    "    preds = np.zeros_like(target_array)\n",
    "    for train_idx,test_idx in train_gen:\n",
    "        #Test features\n",
    "        t_feats = feat_array[train_idx]\n",
    "        t_feats_fft = feat_fft_array[train_idx]\n",
    "        \n",
    "        #Validation features\n",
    "        v_feats = feat_array[test_idx]\n",
    "        v_feats_fft = feat_fft_array[test_idx]\n",
    "        \n",
    "        t_vals = target_array[train_idx]\n",
    "        v_vals = target_array[test_idx]\n",
    "        \n",
    "        pred_classes = np.zeros([v_vals.shape[0],num_surfaces,5])\n",
    "        for k in range(5): #5 time averaging to get more stable results\n",
    "            nnet = get_net_with_fft_mag_only(0.5)\n",
    "            nnet.fit(x=[t_feats,t_feats_fft],y=t_vals,batch_size=256,epochs=3000,validation_data=([v_feats,v_feats_fft],v_vals),verbose=2)\n",
    "            pred_classes[:,:,k] = nnet.predict([v_feats,v_feats_fft])\n",
    "        pred_classes = np.mean(pred_classes,axis=2)\n",
    "        pred_classes = np.argmax(pred_classes,axis=1)\n",
    "        preds[test_idx] = pred_classes\n",
    "        print('Val accuracy: ',accuracy_score(v_vals,pred_classes))\n",
    "        pred_classes = nnet.predict([t_feats,t_feats_fft])\n",
    "        pred_classes = np.argmax(pred_classes,axis=1)\n",
    "        print('Train accuracy: ',accuracy_score(t_vals,pred_classes))\n",
    "    print('5 Fold accuracy: ', accuracy_score(target_array,preds))\n",
    "else:\n",
    "    t_feats = feat_array[:3810]\n",
    "    t_feats_fft = feat_fft_array[:3810]\n",
    "    t_vals = target_array[:3810]\n",
    "    v_feats = feat_array[3810:]\n",
    "    v_feats_fft = feat_fft_array[3810:]\n",
    "    pred_classes = np.zeros([v_feats.shape[0],num_surfaces,3])\n",
    "    for k in range(3):\n",
    "        nnet = get_net_with_fft_mag_only(0.5)\n",
    "        nnet.fit(x=[t_feats,t_feats_fft],y=t_vals,batch_size=256,epochs=3000,verbose=0)\n",
    "        pred_classes[:,:,k] = nnet.predict([v_feats,v_feats_fft])\n",
    "    pred_classes = np.mean(pred_classes,axis=2)\n",
    "    pred_classes = list(np.argmax(pred_classes,axis=1))\n",
    "    pred_classes = [le.inverse_transform([i])[0] for i in pred_classes]\n",
    "    sub_df = pd.read_csv('../input/sample_submission.csv')\n",
    "    sub_df['surface'] = pred_classes\n",
    "    sub_df.to_csv('submission.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
