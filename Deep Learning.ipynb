{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import talos as ta\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import pprint\n",
    "pp = pprint.PrettyPrinter(indent = 4)\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.optimizers import *\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.datasets import mnist\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "\n",
    "from sklearn.metrics import *\n",
    "from sklearn.model_selection import *\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn import preprocessing\n",
    "le = preprocessing.LabelEncoder()\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import keras\n",
    "from keras.layers import *\n",
    "from keras.callbacks import *\n",
    "from keras.models import Model, Sequential\n",
    "from keras import backend as K\n",
    "from keras.engine.topology import Layer\n",
    "from keras import initializers, regularizers, constraints, optimizers, layers\n",
    "from keras.layers import LeakyReLU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = pd.read_csv('target.csv')\n",
    "data = pd.read_csv('data.csv')\n",
    "test = pd.read_csv('test.csv')\n",
    "vdata = pd.read_csv('vdata.csv')\n",
    "vtarget = pd.read_csv('vtarget.csv')\n",
    "wdata = pd.read_csv('whole_data.csv', header=None)\n",
    "wtarget = pd.read_csv('whole_target.csv', header=None)\n",
    "\n",
    "winedata = pd.read_csv('winedata.csv', header=None)\n",
    "\n",
    "ccdata = pd.read_csv('creditcard.csv', header=None)\n",
    "\n",
    "irisdata = pd.read_csv('irisdata.csv', header=None)\n",
    "iristarget = pd.read_csv('iristarget.csv', header=None)\n",
    "\n",
    "print('Data is ready !!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decode_dic = {0: 'fine_concrete',\n",
    "              1: 'concrete',\n",
    "              2: 'soft_tiles',\n",
    "              3: 'tiled',\n",
    "              4: 'soft_pvc',\n",
    "              5: 'hard_tiles_large_space',\n",
    "              6: 'carpet',\n",
    "              7: 'hard_tiles',\n",
    "              8: 'wood'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.values\n",
    "vdata = vdata.values\n",
    "test = test.values\n",
    "target = target['surface']\n",
    "vtarget = vtarget['surface']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(target.shape)\n",
    "print(vtarget.shape)\n",
    "print(btarget.shape)\n",
    "print(bvtarget.shape)\n",
    "print(vdata.shape)\n",
    "print(data.shape)\n",
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# data = data.reshape((2804, 128, 23))\n",
    "# vdata = vdata.reshape((1006, 128, 23))\n",
    "# test = test.reshape((3816, 128, 23))\n",
    "\n",
    "data = data.reshape((358912, 23))\n",
    "vdata = vdata.reshape((128768, 23))\n",
    "test = test.reshape((488448, 23))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "# data = data.reshape((2804, 128, 23))\n",
    "# vdata = vdata.reshape((1006, 128, 23))\n",
    "# test = test.reshape((3816, 128, 23))\n",
    "num_classes = 9\n",
    "\n",
    "\n",
    "# model.add(Conv1D(16, (3,), padding='same', input_shape=data.shape[1:], use_bias=False, kernel_regularizer=regularizers.l2(0.001)))\n",
    "# model.add(BatchNormalization())\n",
    "# model.add(Activation('tanh'))\n",
    "# model.add(Conv1D(16, (3,), use_bias=False, kernel_regularizer=regularizers.l2(0.001)))\n",
    "# model.add(BatchNormalization())\n",
    "# model.add(Activation('tanh'))\n",
    "# model.add(MaxPooling1D(pool_size=(2,)))\n",
    "# # model.add(SpatialDropout1D(0.25))\n",
    "\n",
    "# model.add(Conv1D(64, (3,), padding='same', use_bias=False, kernel_regularizer=regularizers.l2(0.001)))\n",
    "# model.add(BatchNormalization())\n",
    "# model.add(Activation('tanh'))\n",
    "# model.add(Conv1D(64, (3,), use_bias=False, kernel_regularizer=regularizers.l2(0.001)))\n",
    "# model.add(BatchNormalization())\n",
    "# model.add(Activation('tanh'))\n",
    "# model.add(MaxPooling1D(pool_size=(2,)))\n",
    "# # model.add(SpatialDropout1D(0.25))\n",
    "\n",
    "\n",
    "# model.add(Flatten())\n",
    "# model.add(LSTM(128, use_bias=False, kernel_regularizer=regularizers.l2(0.001)))\n",
    "# model.add(BatchNormalization())\n",
    "# model.add(Activation('tanh'))\n",
    "model.add(Dense(64, input_dim=23, use_bias=False, kernel_regularizer=regularizers.l2(0.001)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('tanh'))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(64, use_bias=False, kernel_regularizer=regularizers.l2(0.001)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('tanh'))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(64, use_bias=False, kernel_regularizer=regularizers.l2(0.001)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('tanh'))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(num_classes))\n",
    "model.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = keras.optimizers.rmsprop(lr=0.0001, decay=1e-6)\n",
    "# Let's train the model using RMSprop\n",
    "model.compile(loss='sparse_categorical_crossentropy',\n",
    "              optimizer=opt,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# loss='mearn_squared_error'\n",
    "# 'adam'\n",
    "# 'Nadam'\n",
    "# loss = kullback_leibler_divergence\n",
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(data, btarget,\n",
    "              batch_size=128,\n",
    "              epochs=100,\n",
    "              validation_data=(vdata, bvtarget),\n",
    "              shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model.predict_classes(test)\n",
    "preds = preds[0:-1:128]\n",
    "sub['surface'] = preds\n",
    "sub['surface'] = sub['surface'].map(decode_dic)\n",
    "sub.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = {'activation':['tanh', 'relu'],\n",
    "         'last_activation': ['softmax'],\n",
    "         'optimizer': ['Nadam', 'Adam', 'RMSprop'],\n",
    "         'losses': ['sparse_categorical_crossentropy'],\n",
    "         'first_neuron':[8, 16, 32, 64, 128],\n",
    "         'hidden_layers':[0, 1, 2],\n",
    "         'kernel_initializer': ['uniform','normal'],\n",
    "         'batch_size': [10,20,30,40,60,100],\n",
    "         'dropout': (0, 0.5, 10),\n",
    "         'shapes':['brick','long_funnel'],\n",
    "         'weight_regulizer': [None],\n",
    "         'epochs': [200]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def kaggle_model(x_train, y_train, x_val, y_val, params):\n",
    "\n",
    "    model = Sequential()\n",
    "        \n",
    "    model.add(Dense(params['first_neuron'], input_dim=23, activation=params['activation'], kernel_initializer=params['kernel_initializer']))\n",
    "    model.add(Dropout(params['dropout']))\n",
    "        \n",
    "    ta.model.hidden_layers(model, params, 1)\n",
    "        \n",
    "    model.add(Dense(9, activation=params['last_activation'], kernel_initializer=params['kernel_initializer']))\n",
    "        \n",
    "    model.compile(optimizer=params['optimizer'], loss=params['losses'], metrics=['acc'])\n",
    "\n",
    "    out = model.fit(data, btarget,\n",
    "                         batch_size=params['batch_size'],\n",
    "                         epochs=params['epochs'],\n",
    "                         validation_data=(vdata, bvtarget),\n",
    "                         verbose=0)\n",
    "\n",
    "    return out, model\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scan_object = ta.Scan(data, btarget, model=kaggle_model, params=p, grid_downsample=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scan_object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(optimizer, learning_rate, activation, dropout_rate,\n",
    "                initilizer,num_unit):\n",
    "    keras.backend.clear_session()\n",
    "    model = Sequential()\n",
    "    model.add(Dense(num_unit, kernel_initializer=initilizer,\n",
    "                    activation=activation, input_shape=(784,)))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(num_unit, kernel_initializer=initilizer,\n",
    "                    activation=activation))\n",
    "    model.add(Dropout(dropout_rate)) \n",
    "    model.add(Dense(10, activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer=optimizer(lr=learning_rate),\n",
    "                  metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_train = x_train.reshape(60000, 784)\n",
    "x_test = x_test.reshape(10000, 784)\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [:1] is for testing\n",
    "\n",
    "batch_size = [20, 50, 100][:1]\n",
    "\n",
    "epochs = [1, 20, 50][:1]\n",
    "\n",
    "initilizer = ['lecun_uniform', 'normal', 'he_normal', 'he_uniform'][:1]\n",
    "\n",
    "learning_rate = [0.1, 0.001, 0.02][:1]\n",
    "\n",
    "dropout_rate = [0.3, 0.2, 0.8][:1]\n",
    "\n",
    "num_unit = [10, 5][:1]\n",
    "\n",
    "activation = ['relu', 'tanh', 'sigmoid', 'hard_sigmoid', 'linear'][:1]\n",
    "\n",
    "optimizer = [SGD, RMSprop, Adagrad, Adadelta, Adam, Adamax, Nadam][:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creat the wrapper and pass params to GridSearchCV \n",
    "# parameters is a dict with all values\n",
    "\n",
    "parameters = dict(batch_size = batch_size,\n",
    "                  epochs = epochs,\n",
    "                  dropout_rate = dropout_rate,\n",
    "                  num_unit = num_unit,\n",
    "                  initilizer = initilizer,\n",
    "                  learning_rate = learning_rate,\n",
    "                  activation = activation,\n",
    "                  optimizer = optimizer)\n",
    "\n",
    "model = KerasClassifier(build_fn=build_model, verbose=0)\n",
    "\n",
    "models = GridSearchCV(estimator = model, param_grid=parameters, n_jobs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = models.fit(x_train, y_train)\n",
    "print('Best model :')\n",
    "pp.pprint(best_model.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
