{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = pd.read_csv('target.csv')\n",
    "data = pd.read_csv('data.csv')\n",
    "test = pd.read_csv('test.csv')\n",
    "vdata = pd.read_csv('vdata.csv')\n",
    "vtarget = pd.read_csv('vtarget.csv')\n",
    "wdata = pd.read_csv('whole_data.csv', header=None)\n",
    "wtarget = pd.read_csv('whole_target.csv', header=None)\n",
    "\n",
    "winedata = pd.read_csv('winedata.csv', header=None)\n",
    "\n",
    "ccdata = pd.read_csv('creditcard.csv', header=None)\n",
    "\n",
    "irisdata = pd.read_csv('irisdata.csv', header=None)\n",
    "iristarget = pd.read_csv('iristarget.csv', header=None)\n",
    "\n",
    "print('Data is ready !!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decode_dic = {0: 'fine_concrete',\n",
    "              1: 'concrete',\n",
    "              2: 'soft_tiles',\n",
    "              3: 'tiled',\n",
    "              4: 'soft_pvc',\n",
    "              5: 'hard_tiles_large_space',\n",
    "              6: 'carpet',\n",
    "              7: 'hard_tiles',\n",
    "              8: 'wood'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Attention(Layer):\n",
    "    def __init__(self, step_dim, W_regularizer=None, b_regularizer=None, W_constraint=None, b_constraint=None, bias=True, **kwargs):\n",
    "        self.supports_masking = True\n",
    "        self.init = initializers.get('glorot_uniform')\n",
    "        self.W_regularizer = regularizers.get(W_regularizer)\n",
    "        self.b_regularizer = regularizers.get(b_regularizer)\n",
    "        self.W_constraint = constraints.get(W_constraint)\n",
    "        self.b_constraint = constraints.get(b_constraint)\n",
    "        self.bias = bias\n",
    "        self.step_dim = step_dim\n",
    "        self.features_dim = 0\n",
    "        super(Attention, self).__init__(**kwargs)\n",
    "        \n",
    "    def build(self, input_shape):\n",
    "        assert len(input_shape) == 3\n",
    "        self.W = self.add_weight((input_shape[-1],), initializer=self.init, name='{}_W'.format(self.name), regularizer=self.W_regularizer, constraint=self.W_constraint)\n",
    "        self.features_dim = input_shape[-1]\n",
    "        if self.bias:\n",
    "            self.b = self.add_weight((input_shape[1],), initializer='zero', name='{}_b'.format(self.name), regularizer=self.b_regularizer, constraint=self.b_constraint)\n",
    "        else:\n",
    "            self.b = None\n",
    "        self.built = True\n",
    "\n",
    "    def compute_mask(self, input, input_mask=None):\n",
    "        return None\n",
    "\n",
    "    def call(self, x, mask=None):\n",
    "        features_dim = self.features_dim\n",
    "        step_dim = self.step_dim\n",
    "        eij = K.reshape(K.dot(K.reshape(x, (-1, features_dim)), K.reshape(self.W, (features_dim, 1))), (-1, step_dim))\n",
    "        if self.bias: eij += self.b\n",
    "        eij = K.tanh(eij)\n",
    "        a = K.exp(eij)\n",
    "        if mask is not None: a *= K.cast(mask, K.floatx())\n",
    "        a /= K.cast(K.sum(a, axis=1, keepdims=True) + K.epsilon(), K.floatx())\n",
    "        a = K.expand_dims(a)\n",
    "        weighted_input = x * a\n",
    "        return K.sum(weighted_input, axis=1)\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return input_shape[0],  self.features_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_model():\n",
    "    inp = Input(shape=(128, 10))\n",
    "    x = Bidirectional(CuDNNLSTM(32, return_sequences=True))(inp)\n",
    "    x = Attention(128)(x)\n",
    "    x = Dense(32, activation='relu')(x)\n",
    "    x = Dropout(.5)(x)\n",
    "    x = Dense(9, activation=\"softmax\")(x)\n",
    "    model = Model(inputs=inp, outputs=x)\n",
    "    model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def k_folds(X, y, X_test, k=5):\n",
    "    folds = list(StratifiedKFold(n_splits=k).split(X, y))\n",
    "    y_test = np.zeros((X_test.shape[0], 9))\n",
    "    y_oof = np.zeros((X.shape[0]))\n",
    "    \n",
    "    for i, (train_idx, val_idx) in  enumerate(folds):\n",
    "        print(f'Fold {i+1}')\n",
    "        model = make_model()\n",
    "        model.fit(X[train_idx], y[train_idx], batch_size=128, epochs=100, \n",
    "                  validation_data=[validation_part_df, y[val_idx]], verbose=0)\n",
    "        \n",
    "        pred_val = np.argmax(model.predict(X[val_idx]), axis=1)\n",
    "        score = accuracy_score(pred_val, y[val_idx])\n",
    "        y_oof[val_idx] = pred_val\n",
    "        \n",
    "        print(f'Scored {score:.3f} on validation data')\n",
    "        \n",
    "        y_test += model.predict(X_test)\n",
    "        \n",
    "    return y_oof, y_test  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_oof, y_test = k_folds(train_part_df, y_train, X_test, k=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Local CV is {accuracy_score(y_oof, y_train): .4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = np.argmax(y_test, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub['surface'] = y_test\n",
    "sub['surface'] = sub['surface'].map(decode_dic)\n",
    "sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub.to_csv('submission4.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "train_x = pd.read_csv('X_train.csv')\n",
    "train_y = pd.read_csv('y_train.csv')\n",
    "\n",
    "num_test=500\n",
    "\n",
    "def prepare_data(t):\n",
    "    def f(d):\n",
    "        d=d.sort_values(by=['measurement_number'])\n",
    "        return pd.DataFrame({\n",
    "         'lx':[ d['linear_acceleration_X'].values ],\n",
    "         'ly':[ d['linear_acceleration_Y'].values ],\n",
    "         'lz':[ d['linear_acceleration_Z'].values ],\n",
    "         'ax':[ d['angular_velocity_X'].values ],\n",
    "         'ay':[ d['angular_velocity_Y'].values ],\n",
    "         'az':[ d['angular_velocity_Z'].values ],\n",
    "         'ox':[ d['orientation_X'].values ],\n",
    "         'oy':[ d['orientation_Y'].values ],\n",
    "         'oz':[ d['orientation_Z'].values ],\n",
    "         'ow':[ d['orientation_W'].values ],\n",
    "        })\n",
    "\n",
    "    t= t.groupby('series_id').apply(f)\n",
    "    return t\n",
    "\n",
    "\n",
    "def split_shuffle_groups(t):\n",
    "    t= t.copy()\n",
    "\n",
    "    # select randomly some groups (should be weighted by # of samples)\n",
    "\n",
    "    aggcol='surface' # arbitrary; just to get size\n",
    "    gstat= t.groupby('group_id')[aggcol].agg(np.size)\n",
    "    gstat= gstat.reset_index()\n",
    "\n",
    "    import random\n",
    "    random.shuffle\n",
    "\n",
    "    groups = list(zip(gstat['group_id'].values, gstat[aggcol].values))\n",
    "    random.shuffle(groups)\n",
    "    \n",
    "    test_groups= set()\n",
    "    c=0\n",
    "    for gid,len in groups:\n",
    "        if c>=num_test: break\n",
    "        c+=len\n",
    "        test_groups.add(gid)\n",
    "    print(\"test groups:\", test_groups)\n",
    "\n",
    "    ctest = [ i for i,gid in enumerate(t['group_id']) if (gid in test_groups) ]\n",
    "    ctrain = [ i for i,gid in enumerate(t['group_id']) if not (gid in test_groups) ]\n",
    "\n",
    "    random.shuffle(ctrain)\n",
    "    random.shuffle(ctest)\n",
    "\n",
    "    return t.iloc[ctrain], t.iloc[ctest]\n",
    "\n",
    "\n",
    "train= prepare_data(train_x)\n",
    "\n",
    "# merge\n",
    "train=pd.merge(train,train_y[['series_id','group_id','surface']],on='series_id')\n",
    "\n",
    "train_part_df, validation_part_df= split_shuffle_groups(train)\n",
    "\n",
    "print(\"training part of training data set:\", train_part_df.describe())\n",
    "print(\"validation part of training data set:\",validation_part_df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
